pacf(myTS)
ndiffs(x = myTS)
plot(diff(myTS, 1))
fit_arima <- auto.arima(x = myTS)
fit_arima
accuracy(fit_arima) # check for MAPE, MAD, and MSE
acf(fit_arima$residuals)
pacf(fit_arima$residuals)
coef(fit_arima)
forecast_arima <- forecast(fit_arima, h=12)
forecast_arima
plot(forecast_arima, main = "ARIMA Forecast for the Next 12 Months")
accuracy(forecast_arima)
install.packages("openxlsx")
library(openxlsx)
abbeville_data = read.xlsx("Dataset.xlsx", sheet = 2, startRow = 1, colNames = TRUE)
abbeville_data
plot.ts(abbeville_data$Request, ylab = "Number of Exams", xlab = "Months")
plot.ts(abbeville_data$Request, main = "Pattern of Raw Data", ylab = "Number of Exams", xlab = "Months")
install.packages("mice")
library(mice)
md.pattern(abbeville_data)
imputed_data = complete(mice(abbeville_data))
imputed_data
head(imputed_data)
par(mfrow = c(2,1))
plot.ts(abbeville_data$Request, main = "Pattern of Data Before Imputation", ylab = "Number of Exams", xlab = "Months", col = "blue")
plot.ts(imputed_data$Request, main = "Pattern of Data After Imputation", ylab = "Number of Exams", xlab = "Months", col = "red")
par(mfrow = c(1,1))
install.packages("forecast")
fit_data <- ets(imputed_data$Request, model = "ANN")
fit_data
plot.ts(abbeville_data$Request, main = "Pattern of Data Before Imputation", ylab = "Number of Exams", xlab = "Months", col = "blue")
plot.ts(imputed_data$Request, main = "Pattern of Data After Imputation", ylab = "Number of Exams", xlab = "Months", col = "red")
par(mfrow = c(1,1))
install.packages("forecast")
require(forecast)
fit_data <- ets(imputed_data$Request, model = "ANN")
fit_data
accuracy(fit_data)
forecast_value <- forecast(fit_data, 12)
forecast_value
plot(forecast_value, main = "Simple Forecast for the Next 12 Months")
plot(forecast_value, main = "Simple Forecast for the Next 12 Months", ylab = "Number of Exams", xlab = "Months")
accuracy(forecast_value)
summary(forecast_value)
fit_double <- ets(imputed_data$Request, model = "AAN")
fit_double
forecast_double <- forecast(fit_double, 12)
forecast_double
plot(forecast_double, main = "Double Exponential Smoothing Forecast for the Next 12 Months")
plot(forecast_double, main = "Double Exponential Smoothing Forecast for the Next 12 Months", ylab = "Number of Exams", xlab = "Months")
accuracy(forecast_double)
summary(forecast_double)
myTS <- ts(imputed_data$Request)
myTS
plot(myTS, ylab = "Number of requests", xlab = "Months")
acf(myTS)
pacf(myTS)
ndiffs(x = myTS)
plot(diff(myTS, 1))
fit_arima <- auto.arima(x = myTS)
fit_arima
accuracy(fit_arima) # check for MAPE, MAD, and MSE
acf(fit_arima$residuals)
pacf(fit_arima$residuals)
coef(fit_arima)
forecast_arima <- forecast(fit_arima, h=12)
forecast_arima
plot(forecast_arima, main = "ARIMA Forecast for the Next 12 Months")
plot(forecast_arima, main = "ARIMA Forecast for the Next 12 Months", ylab = "Number of Exams", xlab = "Months")
accuracy(forecast_arima)
summary(forecast_arima)
install.packages("openxlsx")
library(openxlsx)
abbeville_data = read.xlsx("Dataset.xlsx", sheet = 2, startRow = 1, colNames = TRUE)
abbeville_data = read.xlsx("Clean_Dataset.xlsx", sheet = 2, startRow = 1, colNames = TRUE)
abbeville_data
plot.ts(abbeville_data$Request, main = "Pattern of Raw Data", ylab = "Number of Exams", xlab = "Months")
install.packages("mice")
library(mice)
md.pattern(abbeville_data)
imputed_data = complete(mice(abbeville_data))
imputed_data
head(imputed_data)
par(mfrow = c(2,1))
plot.ts(abbeville_data$Request, main = "Pattern of Data Before Imputation", ylab = "Number of Exams", xlab = "Months", col = "blue")
plot.ts(imputed_data$Request, main = "Pattern of Data After Imputation", ylab = "Number of Exams", xlab = "Months", col = "red")
par(mfrow = c(1,1))
loans = read.csv("C:/Users/tuhin/OneDrive/Desktop/DS Classes/DS-705/Lesson-9_project1/Project Pt. 1/loans50k.csv", na.rm = TRUE)
summary(filter_data)
loans = read.csv("C:/Users/tuhin/OneDrive/Desktop/DS Classes/DS-705/Lesson-9_project1/Project Pt. 1/loans50k.csv", header = TRUE)
attach(loans)
loans = data.frame(loans)
head(loans)
filter_data = loans[which((status!="") & (status!="Current") & (status!="Late (16-30 days)") & (status!="Late (31-120 days)") & (status!="In Grace Period")), ]
filter_data = data.frame(filter_data)
filter_data$loan_status[filter_data$status == "Fully Paid"] <- "Good"
filter_data$loan_status[(filter_data$status == "Charged Off") | (filter_data$status == "Default")] <- "Bad"
head(filter_data)
summary(filter_data)
filter_data$employed_length [filter_data$length == "< 1 year"] <- "0-1"
filter_data$employed_length [(filter_data$length == "< 1 year") | (filter_data$length == "1 year")] <- "0-1"
filter_data$employed_length [(filter_data$length == "2 year" | "3 year")] <- "2-5"
filter_data$employed_length [filter_data$length == ("2 year" | "3 year")] <- "2-5"
filter_data$employed_length [filter_data$length == ("2 year" || "3 year")] <- "2-5"
filter_data$employed_length [(filter_data$length == "2 year") | (filter_data$length == "3 year") | (filter_data$length == "4 year") | (filter_data$length == "5 year")] <- "2-5"
filter_data$employed_length [(filter_data$length == "6 year") | (filter_data$length == "7 year") | (filter_data$length == "8 year") | (filter_data$length == "9 year")] <- "6-9 year"
filter_data$loan_status[filter_data$status == "Fully Paid"] <- "Good"
filter_data$loan_status[(filter_data$status == "Charged Off") | (filter_data$status == "Default")] <- "Bad"
filter_data$employed_length [(filter_data$length == "< 1 year") | (filter_data$length == "1 year")] <- "0-1 year"
filter_data$employed_length [(filter_data$length == "2 year") | (filter_data$length == "3 year") | (filter_data$length == "4 year") | (filter_data$length == "5 year")] <- "2-5 years"
filter_data$employed_length [(filter_data$length == "6 year") | (filter_data$length == "7 year") | (filter_data$length == "8 year") | (filter_data$length == "9 year")] <- "6-9 years"
filter_data$employed_length [(filter_data$length == "6 year") | (filter_data$length == "7 year") | (filter_data$length == "8 year") | (filter_data$length == "9 year")] <- "10-10+ years"
View(filter_data)
filter_data$employed_length [(filter_data$length == "< 1 year") | (filter_data$length == "1 year")] <- "0-1 year"
filter_data$employed_length [(filter_data$length == "2 years") | (filter_data$length == "3 years") | (filter_data$length == "4 years") | (filter_data$length == "5 years")] <- "2-5 years"
filter_data$employed_length [(filter_data$length == "6 years") | (filter_data$length == "7 years") | (filter_data$length == "8 years") | (filter_data$length == "9 years")] <- "6-9 years"
filter_data$employed_length [(filter_data$length == "10 years") | (filter_data$length == "10+ years")] <- "10-10+ years"
View(filter_data)
filtered_data = subset(filter_data, , -c(status,length))
View(filtered_data)
filtered_data = subset(filter_data, select = -c(status,length))
filtered_data = filter_data[-drop_columns]
drop_columns = c(0,7,11)
filtered_data = filter_data[-drop_columns]
View(filtered_data)
drop_columns = c(1,8,12)
filtered_data = filter_data[-drop_columns]
View(filtered_data)
filter_data$risk_grade[(filter_data$grade == "A") | (filter_data$grade == "B")] <- "least_risk"
filter_data$risk_grade[(filter_data$grade == "C") | (filter_data$grade == "D") | (filter_data$grade == "E")] <- "moderate"
filter_data$risk_grade[(filter_data$grade == "F") | (filter_data$grade == "G")] <- "risky"
View(filter_data)
drop_columns = c(1,6,8,12)
filtered_data = filter_data[-drop_columns] # drop id, grade, length, status,  column
View(filtered_data)
drop_columns = c(1,6,8,12,14)
filtered_data = filter_data[-drop_columns] # drop id, grade, length, status, state column
filter_data$closeAcc[(filter_data$totalAcc - filter_data$openAcc)]
filter_data$closeAcc = filter_data$totalAcc - filter_data$openAcc
View(filter_data)
filter_data$risk_grade[(filter_data$grade == "A") | (filter_data$grade == "B")] <- "least_risk"
filter_data$risk_grade[(filter_data$grade == "C") | (filter_data$grade == "D") | (filter_data$grade == "E")] <- "moderate"
filter_data$risk_grade[(filter_data$grade == "F") | (filter_data$grade == "G")] <- "risky"
filter_data$closeAcc = filter_data$totalAcc - filter_data$openAcc
drop_columns = c(1,6,7,8,12,14,21)
filtered_data = filter_data[-drop_columns] # drop id, grade, employment, length, status, state, totalAcc column
View(filtered_data)
View(filtered_data)
head(filtered_data)
insurance1 = read.csv(file="C:/Users/tuhin/Desktop/Career/Job Search/Project on GitHub/insurance/insurance.csv", header=TRUE, sep=",")
summary(insurance1) # no missing values
# check the datatype of the variables
sapply(insurance1,class)
# check the skewness of variables 'bmi' and 'charges' by histogram, if log transformation needed
hist(insurance1$bmi)
hist(insurance1$charges, main = "Histogram of Charges", xlab = "charges") # havily right skewed
insurance = data.frame(insurance1)
# variable charges is right skewed, it needs the log transformation
insurance$charges = log(insurance$charges)
# Check for coliniarity.
pairs(insurance) # no coliniarity exists between variables.
?pairs
# Check for coliniarity.
pairs(insurance[1:7]) # no coliniarity exists between variables.
insurance = data.frame(insurance1)
# variable charges is right skewed, it needs the log transformation
insurance$charges = log(insurance$charges)
?pairs
# Check for coliniarity.
pairs(insurance[1:7]) # no coliniarity exists between variables.
# Check for coliniarity.
pairs(insurance) # no coliniarity exists between variables.
head(insurance1)
install.packages("psych")
library(psych)
# Check for coliniarity.
pairs(insurance) # no coliniarity exists between variables.
# Check for coliniarity.
pairs(insurance[1,3,4,7]) # no coliniarity exists between variables.
# Check for coliniarity.
pairs(insurance[1,3,4]) # no coliniarity exists between variables.
# Check for coliniarity.
pairs(insurance[,(1,3,4)]) # no coliniarity exists between variables.
# fit linear model
fit_insurance = lm(charges ~., data = insurance)
summary(fit_insurance)
par(mfrow = c(2, 2))
plot(fit_insurance) # residuals plot
par(mfrow = c(1, 1))
library(leaps)
# best subset selection using regsubsets function
regfit_insurance = regsubsets(charges ~ age + sex + bmi + children + smoker + region, data = insurance, nvmax = 6)
plot(regfit_insurance)
plot(regfit_insurance, scale = "adjr2")
reg_summary = summary(regfit_insurance)
reg_summary$bic # BIC value of the regfit
# plot BIC and adjr2 values to find out the best subsets
plot(reg_summary$bic, xlab = "Number of Variables", ylab = "BIC", type = "l", lwd = 2)
plot(reg_summary$adjr2, xlab = "Number of Variables", ylab = "Adjusted R Square", type = "l", lwd = 2)
which.min(reg_summary$bic) # min of BIC
which.min(reg_summary$cp) # min of CP
which.max(reg_summary$adjr2) # max of adjr2
# find the coefficient
coef(regfit_insurance, 6)
# Define a predict() function for regsubsets objects
predict.regsubsets <- function(object, newdata, id, ...){
form = as.formula(object$call[[2]])
mat = model.matrix(form, newdata)
coefi = coef(object, id=id)
xvars = names(coefi)
mat[ , xvars] %*% coefi
}   # end fuction predict.regsubsets
# 10-fold cross-validation
n = dim(insurance)[1]
k = 10
groups = c(rep(1:k,floor(n/k)),1:(n-floor(n/k)*k))
set.seed(14)
cvgroups = sample(groups,n)
group.error = matrix(,nr=6, nc = k) # row = number of variables, column = which fold
for (i in 1:k) {
groupi = (cvgroups == i)
cv.fit = regsubsets(charges ~ age + sex + bmi + children + smoker + region, data = insurance[!groupi,], nvmax = 6)
for (j in 1:6)  {
y.pred = predict(cv.fit, newdata = insurance[groupi,], id = j)
group.error[j,i] = mean((insurance$charges[groupi] - y.pred)^2)
} # end iter over model size
} # end iter over folds
# calculate the MSE of the models
MSE = apply(group.error, 1, mean)
plot(MSE)
std_error = apply(group.error, 1, sd)/sqrt(k) # calculate the standard error
# calculate the standard error
std_error = apply(group.error, 1, sd)/sqrt(k)
std_error[6]
which(MSE <= MSE[6]+std_error[6])
# With 3 variables gives the most parsimonious(simplest) model with a CV error within 1 standard error of the lowest
coef(regfit_insurance, 3)
# 2nd technique Artificial neural network
library(nnet)
head(insurance1)
# fit the model
set.seed(14)
fit_nnet = nnet(charges ~ age + sex + bmi + children + smoker + region, data = insurance1, size = 1, maxit = 200)
summary(fit_nnet)
library(NeuralNetTools)
plotnet(fit_nnet) # neural network plot
# Cross Validation to tune the number of hidden nodes
n2 = dim(insurance1)[1];n2
k2 = 10 #using 10-fold cross-validation
sizes = 1:8 # number of hidden nodes
groups2 = c(rep(1:k2,floor(n2/k2)),1:(n2-floor(n2/k2)*k2)) # n is not perfectly divisable by k
set.seed(100)
cvgroups2 = sample(groups2,n2)
squaredError = matrix( , nr = n2, nc = length(sizes) )
for(i in 1:k2){
groupi = (cvgroups2 == i)
for(j in 1:length(sizes)){
fit = nnet(charges ~ age + sex + bmi + children + smoker + region, data = insurance1[!groupi,],
size = sizes[j], maxit = 1000, linout = T, trace = F)
squaredError[groupi, j] = (insurance1$charges[groupi] - predict(fit, insurance1[groupi,]) )^2
} # end iteration over j
} # end iteration over i
MSE_nnet = apply(squaredError, 2, mean); MSE_nnet
plot(sizes, MSE_nnet, type="l", lwd=2, las=1)
min(MSE_nnet)
which(MSE_nnet == min(MSE_nnet)) # find out the best hidden nodes
head(insurance1)
# standerdized the numeric variables to reduce the influences of any variable
insurance1$charges = scale(insurance1$charges)
insurance1$bmi = scale(insurance1$bmi)
insurance1$age = scale(insurance1$age)
set.seed(100)
# fit the model
fit_nnet2 = nnet(charges ~ age + sex + bmi + children + smoker + region, data = insurance1,
size = 4, maxit = 1000, linout = T)
summary(fit_nnet2)
fit_nnet2$convergence # check the convergence
plotnet(fit_nnet2)
garson(fit_nnet2) # most important variables of the model
install.packages(c("ergm", "igraph", "intergraph"))
install.packages(c("ergm", "igraph", "intergraph", "statnet"))
data("Moreno")
library(UserNetR)
install.packages("UserNet")
library(UserNetR)
install.packages("UserNetR")
library(UserNetR)
install.packages("UserNetR")
library(UserNetR)
install.packages("devtools")
install.packages("UserNetR")
library(UserNetR)
devtools::install_github("DougLuke/UserNetR")
data("Moreno")
data("Facebook")
# install.packages("UserNetR")
library(UserNetR)
data("Moreno")
data("Facebook")
data("TCnetworks")
data(package = "UserNetR")
library(igraph)
library(intergraph)
iMoreno <- asIgraph(Moreno)
ifacebook <- asIgraph(Facebook)
#
#iMoreno <- asIgraph(Moreno)
#ifacebook <- asIgraph(Facebook)
class(Facebook)
class(TCnetworks)
imoreno_ver <- as_data_frame(iMoreno,what="vertices")
imoreno_edg <- as_data_frame(iMoreno,what="edges")
#Write CSV files
write.csv(imoreno_ver, file = "imoreno_ver.csv") # csv file for Vertices
write.csv(imoreno_edg, file = "imoreno_edg.csv") # csv file for Edges
ifb_ver <- as_data_frame(Facebook,what="vertices")
ifb_edg <- as_data_frame(Facebook,what="edges")
write.csv(ifb_ver, file = "ifb_ver_ver.csv") # csv file for Vertices
write.csv(ifb_edg, file = "ifb_ver_edg.csv") # csv file for Edges
# community detection algorithms
cwF <- cluster_walktrap(Facebook)
modularity(cwF)
membership(cwF)
cebF <- cluster_edge_betweenness(Facebook)
plot(cw1,lhdsi)
cebF <- cluster_edge_betweenness(Facebook)
modularity(cebF)
membership(cebF)
cfgF <- cluster_fast_greedy(Facebook)
modularity(cfgF)
membership(cfgF)
clpF <- cluster_label_prop(Facebook)
modularity(clpF)
membership(clpF)
cleF <- cluster_leading_eigen(Facebook)
modularity(cleF)
membership(cleF)
clF <- cluster_louvain(Facebook)
modularity(clF)
membership(clF)
coF <- cluster_optimal(Facebook)
modularity(coF)
membership(coF)
?Facebook
table(V(Facebook)$group,membership(cwF))
compare(as.numeric(factor(V(Facebook)$group)),cwF,method="adjusted.rand")
compare(cwF,cebF,method="adjusted.rand")
#compare(cw1,cs1,method="adjusted.rand")
compare(cwF,cfgF,method="adjusted.rand")
op <- par(mfrow=c(3,2),mar=c(3,0,2,0))
plot(cebF,Facebook,vertex.label=V(Facebook)$group,main="Edge Betweenness")
plot(cfgF,Facebook,vertex.label=V(Facebook)$group,main="Fastgreedy")
plot(clpF,Facebook,vertex.label=V(Facebook)$group,main="Label Propagation")
plot(cleF,Facebook,vertex.label=V(Facebook)$group,main="Leading Eigenvector")
#plot(cs1,lhdsi,vertex.label=V(lhdsi)$hivscreen,main="Spinglass")
plot(cwF,Facebook,vertex.label=V(Facebook)$group,main="Walktrap")
par(op)
library(ergm)
model0 <- ergm( Facebook ~ edges )
summary( null )
nullsim <- simulate(null, verbose = TRUE,seed = 5)
library(UserNetR)
data( lhds )
lhds
summary(lhds)
library(igraph)
library(intergraph)
class(lhds) # check that the lhds is a network object
lhdsi = asIgraph(lhds) # converts into igraph object
# Extract data frames with node and edge informatoin
lhdsi_ver <- as_data_frame(lhdsi,what="vertices")
lhdsi_edg <- as_data_frame(lhdsi,what="edges")
#Write CSV files
write.csv(lhdsi_ver, file = "lhds_V.csv") # csv file for Vertices
write.csv(lhdsi_edg, file = "lhds_e.csv") # csv file for Edges
# Density of the original network
graph.density(lhdsi)
# Create a subset of the lhdsi network using the population greater than 40 thousand(.04 million)
lhdsi_2 <- subgraph.edges(lhdsi, V(lhdsi)[popmil > .04])
graph.density(lhdsi_2)
# Modularity
table(V(lhdsi)$hivscreen)
# community detection algorithms
cw1 <- cluster_walktrap(lhdsi)
membership(cw1)
modularity(cw1)
plot(cw1,lhdsi, main="Walktrap")
ceb1 <- cluster_edge_betweenness(lhdsi)
modularity(ceb1)
membership(ceb1)
plot(ceb1, lhdsi,main="Edge Betweenness")
cfg1 <- cluster_fast_greedy(lhdsi)
modularity(cfg1)
membership(cfg1)
plot(cfg1, lhdsi,main="Fastgreedy")
clp1 <- cluster_label_prop(lhdsi)
# Read the data
suicide = read.csv(file = "C:/Users/Career/Job Search/Project on GitHub/Viz Project/suicide.csv")
# Read the data
suicide = read.csv(file = "C:/Users/Career/Job Search/Project on GitHub/Viz Project/suicide.csv")
# Read the data
suicide = read.csv(file = "C:/Users/tuhin/Desktop/Career/Job Search/Project on GitHub/Viz Project/suicide.csv")
# Show the first few rows of the dataset
head(suicide)
names(suicide)
colnames(suicide)[which(names(suicide) == "Ã¯..country")] <- "country"
names(suicide)
USA_data = suicide[(which(suicide$country == "United States")), ]
USA_data[1:5,]
USA_data = data.frame(USA_data[,1:6])
# Make a data frame
USA_data = data.frame(USA_data[,1:6])
USA_data[1:5,]
attach(USA_data)
num <- aggregate(suicides_no ~ year, USA_data, sum)
plot(num, main = "Yearly Suicide Rate in USA", xlab = "Year", ylab = "Number of Suicides", col = "blue", lwd = 2, ylim = c(25000,45000))
?aggregate
barplot(height = num$suicides_no, names.arg = num$year, main = "Yearly Suicide Rate in USA",
xlab = "Year", ylab = "Number of Suicides", col = "gray87")
plot(num$year,num$suicides_no,type = "l", main = "Yearly Suicide Rate in USA",
xlab = "Year", ylab = "Number of Suicides", col = "red", lwd = 2, ylim = c(25000,45000))
male = USA_data[which(USA_data$sex == "male"),]
num_male = aggregate(male$suicides_no ~ male$year, male, sum)
num_male
plot(num_male, col = "blue", lwd = 2)
female = USA_data[which(USA_data$sex == "female"),]
num_female = aggregate(female$suicides_no ~ female$year, female, sum)
num_female
plot(num_male$`male$year`, num_male$`male$suicides_no`,type = "l", col = "blue", lwd = 2)
lines(num_female$`female$year`,num_female$`female$suicides_no`,type = "l", col = "red", lwd = 2)
plot(num_male$suicides_no,num_male$year, ylim = c(25000, 35000))
male = USA_data[which(USA_data$sex == "male"),]
num_male = aggregate(male$suicides_no ~ male$year, male, sum)
num_male
plot(num_male, col = "blue", lwd = 2)
female = USA_data[which(USA_data$sex == "female"),]
num_female = aggregate(female$suicides_no ~ female$year, female, sum)
num_female
plot(num_female, col = "red", lwd = 2)
plot(num_male$`male$year`, num_male$`male$suicides_no`,type = "l", col = "blue", lwd = 2)
lines(num_female$`female$year`,num_female$`female$suicides_no`,type = "l", col = "red", lwd = 2)
lines(num_female$`female$year`,num_female$`female$suicides_no`,type = "l", col = "red", lwd = 2)
plot(num_male$suicides_no,num_male$year, ylim = c(25000, 35000))
lines(num_female$year,num_female$suicides_no)
male = USA_data[which(USA_data$sex == "male"),]
num_male = aggregate(male$suicides_no ~ male$year, male, sum)
num_male
plot(num_male, col = "blue", lwd = 2)
female = USA_data[which(USA_data$sex == "female"),]
num_female = aggregate(female$suicides_no ~ female$year, female, sum)
num_female
plot(num_female, col = "red", lwd = 2)
plot(num_male$`male$year`, num_male$`male$suicides_no`,type = "l", col = "blue", lwd = 2)
lines(num_female$`female$year`,num_female$`female$suicides_no`,type = "l", col = "red", lwd = 2)
plot(num_male$suicides_no,num_male$year)
plot(num_male$male$year, num_male$male$suicides_no, type = "l", col = "blue", lwd = 2)
lines(num_female$female$year, num_female$female$suicides_no, type = "l", col = "red", lwd = 2)
plot(num_male$male$year, num_male$male$suicides_no, type = "l", col = "blue", lwd = 2)
plot(num_male$`male$year`, num_male$`male$suicides_no`,type = "l", col = "blue", lwd = 2)
plot(num_male$`male$year`, num_male$`male$suicides_no`,type = "l", col = "blue", lwd = 2, xlab = "Year", ylab = "Number of Suicides")
plot(num_female, col = "red", lwd = 2)
plot(num_male, col = "blue", lwd = 2)
plot(num_female, col = "red", lwd = 2)
plot(num_male$`male$year`, num_male$`male$suicides_no`,type = "l", col = "blue", lwd = 2,
xlab = "Year", ylab = "Number of Suicides", ylim = c(5000,45000))
lines(num_female$`female$year`,num_female$`female$suicides_no`,type = "l", col = "red", lwd = 2)
plot(num_male$suicides_no,num_male$year)
# Compare the trend between male and female
plot(num_male$`male$year`, num_male$`male$suicides_no`,type = "l", col = "blue", lwd = 2,
xlab = "Year", ylab = "Number of Suicides", ylim = c(5000,45000))
lines(num_female$`female$year`,num_female$`female$suicides_no`,type = "l", col = "red", lwd = 2)
?plot
# Compare the trend between male and female
plot(num_male$`male$year`, num_male$`male$suicides_no`,type = "l", col = "blue", lwd = 2, main = "Yearly Suicide Rate in USA"
xlab = "Year", ylab = "Number of Suicides", ylim = c(5000,45000), legend = TRUE)
# Compare the trend between male and female
plot(num_male$`male$year`, num_male$`male$suicides_no`,type = "l", col = "blue", lwd = 2, main = "Yearly Suicide Rate in USA",
xlab = "Year", ylab = "Number of Suicides", ylim = c(5000,45000))
lines(num_female$`female$year`,num_female$`female$suicides_no`,type = "l", col = "red", lwd = 2,
legend = c("Line 1", "Line 2"), col=c("red", "blue"))
lines(num_female$`female$year`,num_female$`female$suicides_no`,type = "l", col = "red", lwd = 2)
legend(1, 1, legend=c("Line 1", "Line 2"), col=c("red", "blue"), lty=1:2, cex=0.8, title="Line types", text.font=4)
legend(1, 1, legend=c("Line 1", "Line 2"), col=c("red", "blue"), lty=1:2, cex=0.8, title="Line types", text.font=4)
# Compare the trend between male and female
plot(num_male$`male$year`, num_male$`male$suicides_no`,type = "l", col = "blue", lwd = 2, main = "Yearly Suicide Rate in USA",
xlab = "Year", ylab = "Number of Suicides", ylim = c(5000,45000))
lines(num_female$`female$year`,num_female$`female$suicides_no`,type = "l", col = "red", lwd = 2)
legend(1, 1, legend=c("Line 1", "Line 2"), col=c("red", "blue"), lty=1:2, cex=0.8, title="Line types", text.font=4)
legend(1, 1, legend=c("Line 1", "Line 2"), col=c("red", "blue"), lty=1:2, cex=0.8, title="Line types", text.font=4, bg='lightblue')
legend('topright', names(a)[-1] , lty=1, col=c('red', 'blue'), bty='n', cex=.75)
legend('topright', names("a")[-1] , lty=1, col=c('red', 'blue'), bty='n', cex=.75)
?legend
legend("topright",    "(x,y)", pch=1, title= "topright, inset = .02",inset = .02)
legend("topleft", "(Male,Female)", pch=1, col = c("blue","red"), bty = 'n')
legend("topleft", names("Male","Female")[-1], lty=1, col = c("blue","red"), bty = 'n')
legend("topleft", c("ldeaths", "+100"), col = c("black", "red"), lty = 1)
# Compare the trend between male and female
plot(num_male$`male$year`, num_male$`male$suicides_no`,type = "l", col = "blue", lwd = 2, main = "Yearly Suicide Rate in USA",
xlab = "Year", ylab = "Number of Suicides", ylim = c(5000,45000))
lines(num_female$`female$year`,num_female$`female$suicides_no`,type = "l", col = "red", lwd = 2)
legend("topleft", c("Male", "Female"), col = c("blue", "red"), lty = 1)
legend("topleft", c("Male", "Female"), col = c("blue", "red"), lty = 0.5)
# Compare the trend between male and female
plot(num_male$`male$year`, num_male$`male$suicides_no`,type = "l", col = "blue", lwd = 2, main = "Yearly Suicide Rate in USA",
xlab = "Year", ylab = "Number of Suicides", ylim = c(5000,45000))
lines(num_female$`female$year`,num_female$`female$suicides_no`,type = "l", col = "red", lwd = 2)
legend("topleft", c("Male", "Female"), col = c("blue", "red"), lty = 1)
legend("topleft", c("Male", "Female"), col = c("blue", "red"), lty = 2)
1
legend("topleft", c("Male", "Female"), col = c("blue", "red"), lty = 1)
